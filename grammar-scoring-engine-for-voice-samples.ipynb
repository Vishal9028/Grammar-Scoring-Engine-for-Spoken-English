{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:26:47.795142Z","iopub.execute_input":"2025-04-07T16:26:47.795476Z","iopub.status.idle":"2025-04-07T16:26:49.020551Z","shell.execute_reply.started":"2025-04-07T16:26:47.795454Z","shell.execute_reply":"2025-04-07T16:26:49.019248Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/shl-intern-hiring-assessment/dataset/sample_submission.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_885.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_698.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1176.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1215.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_66.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_386.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1026.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_330.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_72.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_858.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_107.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_820.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_300.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_435.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_550.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_841.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_641.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_290.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_401.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_321.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_20.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_348.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_500.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_735.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_888.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_959.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_276.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1323.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1089.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1289.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_29.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_676.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_811.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_762.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1183.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1297.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_709.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_281.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_308.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1054.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_662.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_525.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_633.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_274.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_922.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_683.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1275.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_541.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_113.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_665.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_543.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1012.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_759.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_225.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_644.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1035.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1159.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1179.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1048.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_499.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1123.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1116.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_521.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1013.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_198.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1278.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_4.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_165.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_19.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_261.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_998.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_89.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1280.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_971.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_322.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1058.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1068.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_719.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1205.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1315.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1061.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1091.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_75.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_217.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_95.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_159.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_545.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_379.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_137.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1124.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_177.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_180.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_726.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1081.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_519.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_285.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_569.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_800.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_218.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_148.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_408.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1122.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_884.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_488.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_733.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_235.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_286.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_263.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1022.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_656.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1101.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1286.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_287.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1293.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_692.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1190.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1173.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_388.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_767.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1242.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1311.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_540.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_932.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_448.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_949.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_908.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_158.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_172.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_958.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_805.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_746.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_221.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_391.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_21.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1169.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_68.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_529.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_138.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1195.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_580.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_360.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1033.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1240.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_10.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_48.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1193.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1217.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1292.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_282.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_599.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_153.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_564.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1019.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_196.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1115.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_103.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1291.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_690.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_706.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1214.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1138.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_831.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_857.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1267.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_135.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_433.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_556.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_306.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_109.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1256.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_34.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_572.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_487.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_554.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_512.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1317.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_179.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_604.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_882.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_437.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_920.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_546.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1178.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_702.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1243.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_394.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_428.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1321.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_422.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_713.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_320.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_770.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_1166.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_151.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test/audio_897.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_90.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_581.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_77.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_817.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_694.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1262.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_237.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_765.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1164.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1251.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1032.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_688.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_886.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1129.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_464.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1040.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_711.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_853.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_436.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_538.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_859.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_547.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1266.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_919.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1036.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_796.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_994.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_760.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_315.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1028.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_55.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1284.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_950.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_256.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_359.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_462.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_44.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_753.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_813.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_7.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1100.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1131.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_119.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_59.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_802.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_518.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_12.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_591.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_536.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1082.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_404.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_254.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_990.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_513.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_653.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1177.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_188.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_539.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_289.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_778.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1210.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_946.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_67.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_186.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_600.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1277.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_291.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_602.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1150.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1118.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1106.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1312.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_495.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_265.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_558.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_82.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_61.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_964.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_526.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1285.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_32.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_535.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_110.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1172.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_567.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1325.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_374.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_944.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_327.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_120.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_297.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1212.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_899.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_516.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_441.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_848.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1103.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_346.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_446.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_104.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1236.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_957.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_776.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1163.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_642.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_479.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_940.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1171.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_563.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_773.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_71.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_76.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_905.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_925.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_205.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_345.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_661.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_102.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1136.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1304.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_399.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1126.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1024.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_45.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_812.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_860.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_942.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_414.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_725.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1245.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_275.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_590.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_955.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_478.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_779.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_2.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_447.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_807.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_223.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1268.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_118.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1202.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_549.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1069.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_366.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_743.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_210.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_874.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_705.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_952.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_836.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_396.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1239.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_909.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_583.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1114.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_771.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_989.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1182.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_865.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_278.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_468.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_930.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_314.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_697.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_722.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_674.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1104.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1134.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1043.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_609.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1329.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1153.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_23.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_542.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_592.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_954.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_916.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_244.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_387.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_313.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1252.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_194.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_427.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_93.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1162.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_142.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_708.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_492.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_934.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_826.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_931.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_255.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_654.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_703.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_657.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_5.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_185.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1175.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1120.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1128.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1066.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_80.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_668.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_8.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_763.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_85.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1318.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_303.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_727.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1057.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_469.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_965.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_202.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_127.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_677.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_788.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_904.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_695.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_463.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1075.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_130.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_273.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_489.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_293.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1030.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_970.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_239.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_252.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_311.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_240.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_288.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1226.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_146.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_643.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_675.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_731.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1191.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_52.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_504.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1112.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_875.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_460.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1111.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_736.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1333.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_365.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_937.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_332.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1335.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_681.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_808.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_766.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_700.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1247.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_686.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1313.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_867.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_939.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_917.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_620.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1099.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_339.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1147.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_921.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_484.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_745.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1274.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1326.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_527.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_948.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_870.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_362.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_873.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_482.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1307.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_680.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_140.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1196.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_582.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_17.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_533.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_154.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_963.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_926.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1264.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1102.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_630.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_730.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_317.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_440.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_611.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_69.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_64.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_978.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_494.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_131.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_336.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_105.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_395.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_324.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_358.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_707.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_15.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_63.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_744.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1038.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_167.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_956.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_716.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_334.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_868.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_854.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_245.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_903.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_834.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1110.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_432.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_236.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1208.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_200.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1078.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1200.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_353.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_947.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_212.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_168.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_352.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_445.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_419.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1332.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_701.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_117.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1059.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_790.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_390.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_586.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_226.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_699.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_363.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_988.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_485.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_241.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_481.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_652.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_424.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_483.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1017.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_890.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1065.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_787.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_627.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1290.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_758.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1314.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_272.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_687.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_809.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_312.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_902.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1296.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_147.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_783.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_144.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_373.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_887.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_443.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_350.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_503.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_62.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_402.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1031.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_116.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_693.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_477.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_413.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1025.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_123.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_133.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_647.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1223.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_980.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_755.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_869.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1148.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_685.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_678.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_53.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1184.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_552.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1216.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1185.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_918.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_250.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_721.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_624.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_43.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_889.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_184.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_842.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1125.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_9.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_455.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1160.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_913.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_493.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_704.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_548.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1230.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_961.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_832.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_33.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_896.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_827.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_748.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_658.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_471.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1117.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_270.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_301.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_576.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_649.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1261.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_640.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_636.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1272.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1135.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_74.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_983.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_993.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_480.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1298.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_876.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_794.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_163.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_450.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_514.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_696.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_389.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1008.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_1187.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_724.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_490.wav\n/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train/audio_259.wav\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install librosa pydub openai-whisper transformers sentencepiece torch pandas scikit-learn language-tool-python spacy nltk\n!python -m spacy download en_core_web_sm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:26:49.021630Z","iopub.execute_input":"2025-04-07T16:26:49.021966Z","iopub.status.idle":"2025-04-07T16:27:00.564082Z","shell.execute_reply.started":"2025-04-07T16:26:49.021935Z","shell.execute_reply":"2025-04-07T16:27:00.562930Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\nRequirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\nRequirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.3)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nRequirement already satisfied: language-tool-python in /usr/local/lib/python3.10/dist-packages (2.9.2)\nRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.2.4)\nRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\nRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\nRequirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\nRequirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.67.1)\nRequirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.9.0)\nRequirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.2.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2025.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (5.9.5)\nRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from language-tool-python) (0.10.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.15.1)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.11.0a2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk) (1.17.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3->librosa) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.11)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.0)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.11.0a2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n\u001b[38;5;2m Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import os\nimport librosa\nimport soundfile as sf\nimport pandas as pd\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:27:00.565953Z","iopub.execute_input":"2025-04-07T16:27:00.566238Z","iopub.status.idle":"2025-04-07T16:27:00.570236Z","shell.execute_reply.started":"2025-04-07T16:27:00.566212Z","shell.execute_reply":"2025-04-07T16:27:00.569447Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Audio Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport soundfile as sf\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Paths\nAUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train'\nCSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv'\nPROCESSED_DIR = '/kaggle/working/processed_audio'\nos.makedirs(PROCESSED_DIR, exist_ok=True)\n\n# Load CSV and rename columns\ntrain_df = pd.read_csv(CSV_PATH)\ntrain_df.columns = ['filename', 'label']  # Rename for easier use\n\n# Preprocessing function\ndef preprocess_audio(file_path, save_path, sr=16000):\n    y, orig_sr = librosa.load(file_path, sr=None)\n    if orig_sr != sr:\n        y = librosa.resample(y, orig_sr, sr)\n    y = y / max(abs(y))  # Normalise volume\n    y, _ = librosa.effects.trim(y, top_db=25)  # Trim silence\n    sf.write(save_path, y, sr)\n\n# Preprocess each audio\nfor filename in tqdm(train_df['filename']):\n    in_path = os.path.join(AUDIO_DIR, filename)\n    out_path = os.path.join(PROCESSED_DIR, filename)\n    preprocess_audio(in_path, out_path)\n\nprint(\" Audio preprocessing completed. Files saved in:\", PROCESSED_DIR)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:27:00.571431Z","iopub.execute_input":"2025-04-07T16:27:00.571625Z","iopub.status.idle":"2025-04-07T16:30:34.548952Z","shell.execute_reply.started":"2025-04-07T16:27:00.571607Z","shell.execute_reply":"2025-04-07T16:30:34.548061Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df23d4428610436096b1a71bdcfae314"}},"metadata":{}},{"name":"stdout","text":" Audio preprocessing completed. Files saved in: /kaggle/working/processed_audio\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"files = os.listdir('/kaggle/working/processed_audio')\nprint(f\" Found {len(files)} preprocessed audio files.\\nExample files:\\n\", files[:5])\n\n# Check sample rate and duration of a random file\nsample_file = os.path.join('/kaggle/working/processed_audio', files[0])\ny, sr = librosa.load(sample_file, sr=None)\n\nduration = librosa.get_duration(y=y, sr=sr)\nprint(f\" Sample file: {files[0]}\")\nprint(f\" Duration: {duration:.2f} seconds\")\nprint(f\" Sample rate: {sr} Hz\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:30:34.549887Z","iopub.execute_input":"2025-04-07T16:30:34.550110Z","iopub.status.idle":"2025-04-07T16:30:34.561783Z","shell.execute_reply.started":"2025-04-07T16:30:34.550091Z","shell.execute_reply":"2025-04-07T16:30:34.561028Z"}},"outputs":[{"name":"stdout","text":" Found 444 preprocessed audio files.\nExample files:\n ['audio_297.wav', 'audio_77.wav', 'audio_836.wav', 'audio_413.wav', 'audio_504.wav']\n Sample file: audio_297.wav\n Duration: 46.82 seconds\n Sample rate: 16000 Hz\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"## Transcribe Audio with Whisper (base model)","metadata":{}},{"cell_type":"code","source":"import torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\" Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:30:34.562632Z","iopub.execute_input":"2025-04-07T16:30:34.562926Z","iopub.status.idle":"2025-04-07T16:30:34.573298Z","shell.execute_reply.started":"2025-04-07T16:30:34.562893Z","shell.execute_reply":"2025-04-07T16:30:34.572391Z"}},"outputs":[{"name":"stdout","text":" Using device: cuda\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import whisper\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport os\n\n\n# Load Whisper ASR model\nmodel = whisper.load_model(\"base\")  # Options: tiny, base, small, medium, large\n\n# Transcribe and collect text\ntranscripts = []\n\nfor fname in tqdm(train_df['filename']):\n    audio_path = os.path.join('/kaggle/working/processed_audio', fname)\n    result = model.transcribe(audio_path, language='en')\n    transcripts.append(result['text'])\n\n# Add transcripts to dataframe\ntrain_df['transcript'] = transcripts\n\n# Save updated CSV\ntrain_df.to_csv('/kaggle/working/train_with_transcripts.csv', index=False)\nprint(\" Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:30:34.574249Z","iopub.execute_input":"2025-04-07T16:30:34.574546Z","iopub.status.idle":"2025-04-07T16:52:07.742743Z","shell.execute_reply.started":"2025-04-07T16:30:34.574506Z","shell.execute_reply":"2025-04-07T16:52:07.741876Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914fe434ce8e4e25a917783117bfd4d5"}},"metadata":{}},{"name":"stdout","text":" Transcriptions saved to: /kaggle/working/train_with_transcripts.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/working/train_with_transcripts.csv')\nprint(\" Columns:\", df.columns.tolist())\nprint(\" Total records:\", len(df))\nprint(\" Sample transcript:\\n\")\nprint(df[['filename', 'label', 'transcript']].head(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:52:07.745606Z","iopub.execute_input":"2025-04-07T16:52:07.745835Z","iopub.status.idle":"2025-04-07T16:52:07.766604Z","shell.execute_reply.started":"2025-04-07T16:52:07.745816Z","shell.execute_reply":"2025-04-07T16:52:07.765756Z"}},"outputs":[{"name":"stdout","text":" Columns: ['filename', 'label', 'transcript']\n Total records: 444\n Sample transcript:\n\n         filename  label                                         transcript\n0  audio_1261.wav    1.0   My favorite hobby is cultivation of plants su...\n1   audio_942.wav    1.5   the playground looks like very clear and neat...\n2  audio_1110.wav    1.5   My goal is to become an electrical employee a...\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Check for empty transcripts\nempty_transcripts = df['transcript'].str.strip().eq('').sum()\nprint(f\" Empty transcripts found: {empty_transcripts}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:52:07.768303Z","iopub.execute_input":"2025-04-07T16:52:07.768528Z","iopub.status.idle":"2025-04-07T16:52:07.774065Z","shell.execute_reply.started":"2025-04-07T16:52:07.768509Z","shell.execute_reply":"2025-04-07T16:52:07.773144Z"}},"outputs":[{"name":"stdout","text":" Empty transcripts found: 0\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Transcript Cleaning","metadata":{}},{"cell_type":"code","source":"import re\n\n# List of common disfluencies and fillers\nFILLERS = ['uh', 'um', 'erm', 'you know', 'like', 'i mean', 'hmm', 'ah', 'uhh', 'huh']\n\ndef clean_transcript(text):\n    text = text.lower()  # Standard casing\n    text = re.sub(r'\\b(?:' + '|'.join(FILLERS) + r')\\b', '', text)  # Remove fillers\n    text = re.sub(r'\\s+', ' ', text)  # Collapse multiple spaces\n    text = re.sub(r'\\s([?.!,\"])', r'\\1', text)  # Remove space before punctuation\n    text = text.strip()\n    return text\n\n# Load previous data\ndf = pd.read_csv('/kaggle/working/train_with_transcripts.csv')\n\n# Clean all transcripts\ndf['cleaned_transcript'] = df['transcript'].astype(str).apply(clean_transcript)\n\n# Save new version\ndf.to_csv('/kaggle/working/train_cleaned.csv', index=False)\nprint(\" Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:52:07.774993Z","iopub.execute_input":"2025-04-07T16:52:07.775268Z","iopub.status.idle":"2025-04-07T16:52:07.838761Z","shell.execute_reply.started":"2025-04-07T16:52:07.775239Z","shell.execute_reply":"2025-04-07T16:52:07.837925Z"}},"outputs":[{"name":"stdout","text":" Cleaned transcripts saved to: /kaggle/working/train_cleaned.csv\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"print(df[['transcript', 'cleaned_transcript']].sample(3))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T16:52:07.839501Z","iopub.execute_input":"2025-04-07T16:52:07.839698Z","iopub.status.idle":"2025-04-07T16:52:07.846317Z","shell.execute_reply.started":"2025-04-07T16:52:07.839681Z","shell.execute_reply":"2025-04-07T16:52:07.845568Z"}},"outputs":[{"name":"stdout","text":"                                            transcript  \\\n212   When the school playground provides a safe ou...   \n192   I'm not going to be able to do it. I'm not go...   \n346   I'm trying to learn more about investing in a...   \n\n                                    cleaned_transcript  \n212  when the school playground provides a safe out...  \n192  i'm not going to be able to do it. i'm not goi...  \n346  i'm trying to learn more about investing in ar...  \n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"## Grammar Feature Extraction","metadata":{}},{"cell_type":"code","source":"import language_tool_python\nimport spacy\nfrom tqdm.notebook import tqdm\n\n# Load grammar checker and NLP parser\ntool = language_tool_python.LanguageTool('en-US')\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Load cleaned data\ndf = pd.read_csv('/kaggle/working/train_cleaned.csv')\n\n# Feature lists\nerror_counts = []\navg_sent_lengths = []\npos_diversities = []\n\nfor text in tqdm(df['cleaned_transcript']):\n    # Grammar Errors\n    matches = tool.check(text)\n    error_counts.append(len(matches))\n    \n    # NLP parsing\n    doc = nlp(text)\n    sent_lengths = [len(sent) for sent in doc.sents]\n    pos_tags = [token.pos_ for token in doc if token.pos_ != 'SPACE']\n    \n    # Features\n    avg_sent_lengths.append(sum(sent_lengths) / len(sent_lengths) if sent_lengths else 0)\n    pos_diversities.append(len(set(pos_tags)))\n\n# Append features\ndf['grammar_errors'] = error_counts\ndf['avg_sentence_length'] = avg_sent_lengths\ndf['pos_diversity'] = pos_diversities\n\n# Save\ndf.to_csv('/kaggle/working/train_features.csv', index=False)\nprint(\" Grammar features saved to: /kaggle/working/train_features.csv\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-07T16:52:07.847396Z","iopub.execute_input":"2025-04-07T16:52:07.847649Z","iopub.status.idle":"2025-04-07T17:08:56.343239Z","shell.execute_reply.started":"2025-04-07T16:52:07.847630Z","shell.execute_reply":"2025-04-07T17:08:56.342314Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d1300f718fc41c190807a071c56d2e5"}},"metadata":{}},{"name":"stdout","text":" Grammar features saved to: /kaggle/working/train_features.csv\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"### Feature Enhancement","metadata":{}},{"cell_type":"code","source":"# Reload if needed\ndf = pd.read_csv('/kaggle/working/train_features.csv')\n\n# Add word count\ndf['word_count'] = df['cleaned_transcript'].apply(lambda x: len(str(x).split()))\n\n# Avoid divide-by-zero\ndf['grammar_errors_per_word'] = df['grammar_errors'] / df['word_count'].replace(0, 1)\n\n# Save enhanced features\ndf.to_csv('/kaggle/working/train_features_enhanced.csv', index=False)\nprint(\" Added word_count and grammar_errors_per_word.\")\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-07T17:08:56.344337Z","iopub.execute_input":"2025-04-07T17:08:56.344708Z","iopub.status.idle":"2025-04-07T17:08:56.377825Z","shell.execute_reply.started":"2025-04-07T17:08:56.344675Z","shell.execute_reply":"2025-04-07T17:08:56.377009Z"}},"outputs":[{"name":"stdout","text":" Added word_count and grammar_errors_per_word.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"### GEC Feature Extraction ","metadata":{}},{"cell_type":"code","source":"!pip install happytransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:08:56.378898Z","iopub.execute_input":"2025-04-07T17:08:56.379215Z","iopub.status.idle":"2025-04-07T17:08:59.844970Z","shell.execute_reply.started":"2025-04-07T17:08:56.379184Z","shell.execute_reply":"2025-04-07T17:08:59.843798Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: happytransformer in /usr/local/lib/python3.10/dist-packages (3.0.0)\nRequirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (2.5.1+cu121)\nRequirement already satisfied: tqdm>=4.43 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (4.67.1)\nRequirement already satisfied: transformers<5.0.0,>=4.30.1 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (4.47.0)\nRequirement already satisfied: datasets<3.0.0,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (2.21.0)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from happytransformer) (0.2.0)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from happytransformer) (3.20.3)\nRequirement already satisfied: accelerate<1.0.0,>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (0.34.2)\nRequirement already satisfied: tokenizers<1.0.0,>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from happytransformer) (0.21.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from happytransformer) (0.19.1)\nRequirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (6.0.2)\nRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.29.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0.0,>=2.13.1->happytransformer) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.11.12)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->happytransformer) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0->happytransformer) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.30.1->happytransformer) (2024.11.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (4.3.6)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (2.11.0a2)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->happytransformer) (75.1.0)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->happytransformer) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.18.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.11)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb->happytransformer) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.13.1->happytransformer) (2025.1.31)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->happytransformer) (3.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.13.1->happytransformer) (2025.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate<1.0.0,>=0.20.1->happytransformer) (2024.2.0)\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from happytransformer import HappyTextToText, TTSettings\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\n# Load cleaned data\ndf = pd.read_csv('/kaggle/working/train_cleaned.csv')\ntexts = df['cleaned_transcript'].astype(str).tolist()\n\n# Load grammar correction model (T5 based)\nhappy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\nargs = TTSettings(num_beams=5, min_length=1)\n\n# Run correction and collect features\nedit_counts = []\nedit_ratios = []\n\nfor text in tqdm(texts):\n    result = happy_tt.generate_text(\"grammar: \" + text, args=args)\n    corrected = result.text\n    \n    # Basic word-level edit count\n    original_words = text.split()\n    corrected_words = corrected.split()\n    edits = sum(1 for o, c in zip(original_words, corrected_words) if o != c)\n    edits += abs(len(original_words) - len(corrected_words))\n    \n    edit_counts.append(edits)\n    edit_ratios.append(edits / max(1, len(original_words)))  # avoid div by zero\n\n# Add to dataframe\ndf['gec_edits'] = edit_counts\ndf['gec_edit_rate'] = edit_ratios\n\n# Save\ndf.to_csv('/kaggle/working/train_gec_features.csv', index=False)\nprint(\" GEC features saved to /kaggle/working/train_gec_features.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:08:59.846211Z","iopub.execute_input":"2025-04-07T17:08:59.846533Z","iopub.status.idle":"2025-04-07T17:15:51.657380Z","shell.execute_reply.started":"2025-04-07T17:08:59.846502Z","shell.execute_reply":"2025-04-07T17:15:51.656621Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/444 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4589bb8415d41adbfca851fb2cd2751"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (1179 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"name":"stdout","text":" GEC features saved to /kaggle/working/train_gec_features.csv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"archis=pd.read_csv('/kaggle/working/train_features.csv')\narchis","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:51.658323Z","iopub.execute_input":"2025-04-07T17:15:51.658597Z","iopub.status.idle":"2025-04-07T17:15:51.687325Z","shell.execute_reply.started":"2025-04-07T17:15:51.658574Z","shell.execute_reply":"2025-04-07T17:15:51.686539Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"           filename  label                                         transcript  \\\n0    audio_1261.wav    1.0   My favorite hobby is cultivation of plants su...   \n1     audio_942.wav    1.5   the playground looks like very clear and neat...   \n2    audio_1110.wav    1.5   My goal is to become an electrical employee a...   \n3    audio_1024.wav    1.5   My favorite place is in Andhra Padesh. It is ...   \n4     audio_538.wav    2.0   My favorite place is UTI and Puraikana. My ex...   \n..              ...    ...                                                ...   \n439   audio_494.wav    5.0   My favorite place to visit is the National Pa...   \n440   audio_363.wav    5.0   The playground looks like an average school p...   \n441   audio_481.wav    5.0   The place that I love to journey to whenever ...   \n442   audio_989.wav    5.0   I'm going to go to the bathroom. I'm going to...   \n443  audio_1163.wav    5.0   My most important goal in life is to build a ...   \n\n                                    cleaned_transcript  grammar_errors  \\\n0    my favorite hobby is cultivation of plants suc...               3   \n1    the playground looks very clear and neat as th...               1   \n2    my goal is to become an electrical employee an...               3   \n3    my favorite place is in andhra padesh. it is i...              16   \n4    my favorite place is uti and puraikana. my exp...              22   \n..                                                 ...             ...   \n439  my favorite place to visit is the national par...              14   \n440  the playground looks an average school playgro...               5   \n441  the place that i love to journey to whenever i...               9   \n442  i'm going to go to the bathroom. i'm going to ...              77   \n443  my most important goal in life is to build a l...               9   \n\n     avg_sentence_length  pos_diversity  \n0              16.500000             10  \n1              20.000000             10  \n2              47.000000             11  \n3              11.000000             12  \n4              11.800000             13  \n..                   ...            ...  \n439            11.833333             12  \n440            18.500000             12  \n441            57.000000             13  \n442             8.662162              9  \n443            29.666667             13  \n\n[444 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n      <th>transcript</th>\n      <th>cleaned_transcript</th>\n      <th>grammar_errors</th>\n      <th>avg_sentence_length</th>\n      <th>pos_diversity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_1261.wav</td>\n      <td>1.0</td>\n      <td>My favorite hobby is cultivation of plants su...</td>\n      <td>my favorite hobby is cultivation of plants suc...</td>\n      <td>3</td>\n      <td>16.500000</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_942.wav</td>\n      <td>1.5</td>\n      <td>the playground looks like very clear and neat...</td>\n      <td>the playground looks very clear and neat as th...</td>\n      <td>1</td>\n      <td>20.000000</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_1110.wav</td>\n      <td>1.5</td>\n      <td>My goal is to become an electrical employee a...</td>\n      <td>my goal is to become an electrical employee an...</td>\n      <td>3</td>\n      <td>47.000000</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1024.wav</td>\n      <td>1.5</td>\n      <td>My favorite place is in Andhra Padesh. It is ...</td>\n      <td>my favorite place is in andhra padesh. it is i...</td>\n      <td>16</td>\n      <td>11.000000</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_538.wav</td>\n      <td>2.0</td>\n      <td>My favorite place is UTI and Puraikana. My ex...</td>\n      <td>my favorite place is uti and puraikana. my exp...</td>\n      <td>22</td>\n      <td>11.800000</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>audio_494.wav</td>\n      <td>5.0</td>\n      <td>My favorite place to visit is the National Pa...</td>\n      <td>my favorite place to visit is the national par...</td>\n      <td>14</td>\n      <td>11.833333</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>audio_363.wav</td>\n      <td>5.0</td>\n      <td>The playground looks like an average school p...</td>\n      <td>the playground looks an average school playgro...</td>\n      <td>5</td>\n      <td>18.500000</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>441</th>\n      <td>audio_481.wav</td>\n      <td>5.0</td>\n      <td>The place that I love to journey to whenever ...</td>\n      <td>the place that i love to journey to whenever i...</td>\n      <td>9</td>\n      <td>57.000000</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>442</th>\n      <td>audio_989.wav</td>\n      <td>5.0</td>\n      <td>I'm going to go to the bathroom. I'm going to...</td>\n      <td>i'm going to go to the bathroom. i'm going to ...</td>\n      <td>77</td>\n      <td>8.662162</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>443</th>\n      <td>audio_1163.wav</td>\n      <td>5.0</td>\n      <td>My most important goal in life is to build a ...</td>\n      <td>my most important goal in life is to build a l...</td>\n      <td>9</td>\n      <td>29.666667</td>\n      <td>13</td>\n    </tr>\n  </tbody>\n</table>\n<p>444 rows  7 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"## Model Training & Evaluation","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"## Feature-Based Model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom scipy.stats import pearsonr\nimport numpy as np\n\n# Load features\ndf = pd.read_csv('/kaggle/working/train_features.csv')\n\n# Features & target\nX = df[['grammar_errors', 'avg_sentence_length', 'pos_diversity']]\ny = df['label']\n\n# Split data\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, y_train)\n\n# Predict on validation\ny_pred = model.predict(X_val)\n\n# Evaluation\nmae = mean_absolute_error(y_val, y_pred)\nrmse = np.sqrt(mean_squared_error(y_val, y_pred))\ncorr, _ = pearsonr(y_val, y_pred)\n\nprint(f\" MAE: {mae:.3f}\")\nprint(f\" RMSE: {rmse:.3f}\")\nprint(f\" Pearson Correlation: {corr:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:51.688172Z","iopub.execute_input":"2025-04-07T17:15:51.688423Z","iopub.status.idle":"2025-04-07T17:15:51.986286Z","shell.execute_reply.started":"2025-04-07T17:15:51.688393Z","shell.execute_reply":"2025-04-07T17:15:51.985587Z"}},"outputs":[{"name":"stdout","text":" MAE: 1.080\n RMSE: 1.225\n Pearson Correlation: 0.111\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"low Pearson correlation (0.206) and high MAE (1.05) suggest the model isn't capturing the true grammar scoring pattern well yet.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom scipy.stats import pearsonr\nimport numpy as np\n\n# Load enhanced data\ndf = pd.read_csv('/kaggle/working/train_features_enhanced.csv')\n\nfeatures = ['grammar_errors', 'avg_sentence_length', 'pos_diversity',\n            'word_count', 'grammar_errors_per_word']\nX = df[features]\ny = df['label']\n\n# Split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Base models\nmodel_rf = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel_lgb = lgb.LGBMRegressor(n_estimators=100, random_state=42)\nmodel_ridge = Ridge(alpha=1.0)\n\n# Train\nmodel_rf.fit(X_train, y_train)\nmodel_lgb.fit(X_train, y_train)\nmodel_ridge.fit(X_train, y_train)\n\n# Predict\npred_rf = model_rf.predict(X_val)\npred_lgb = model_lgb.predict(X_val)\npred_ridge = model_ridge.predict(X_val)\n\n# Ensemble (simple average)\nensemble_pred = (pred_rf + pred_lgb + pred_ridge) / 3\n\n# Evaluation\nmae = mean_absolute_error(y_val, ensemble_pred)\nrmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\ncorr, _ = pearsonr(y_val, ensemble_pred)\n\nprint(f\" Ensemble MAE: {mae:.3f}\")\nprint(f\" Ensemble RMSE: {rmse:.3f}\")\nprint(f\" Ensemble Pearson Correlation: {corr:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:51.987161Z","iopub.execute_input":"2025-04-07T17:15:51.987467Z","iopub.status.idle":"2025-04-07T17:15:54.049257Z","shell.execute_reply.started":"2025-04-07T17:15:51.987436Z","shell.execute_reply":"2025-04-07T17:15:54.048370Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000767 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 371\n[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 5\n[LightGBM] [Info] Start training from score 3.635211\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n Ensemble MAE: 1.035\n Ensemble RMSE: 1.164\n Ensemble Pearson Correlation: 0.202\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"This tells us:\n\n* The extra features (word_count, grammar_errors_per_word) helped\n\n* Ensemble learning smoothed out errors from any one model\n\n* But handcrafted features alone still don't explain enough variance in the grammar scores\n\n","metadata":{}},{"cell_type":"markdown","source":"### Merge (GEC + Existing Features) and Retraining with GEC feature ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load both feature sets\ndf_main = pd.read_csv('/kaggle/working/train_features_enhanced.csv')\ndf_gec = pd.read_csv('/kaggle/working/train_gec_features.csv')\n\n# Join on filename (or row order)\ndf_combined = df_main.copy()\ndf_combined['gec_edits'] = df_gec['gec_edits']\ndf_combined['gec_edit_rate'] = df_gec['gec_edit_rate']\n\n# Save combined version\ndf_combined.to_csv('/kaggle/working/train_all_features.csv', index=False)\nprint(\" Combined feature set saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:54.050185Z","iopub.execute_input":"2025-04-07T17:15:54.050486Z","iopub.status.idle":"2025-04-07T17:15:54.087899Z","shell.execute_reply.started":"2025-04-07T17:15:54.050448Z","shell.execute_reply":"2025-04-07T17:15:54.087237Z"}},"outputs":[{"name":"stdout","text":" Combined feature set saved.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"#### Retrain Ensemble with GEC Features Included","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom scipy.stats import pearsonr\nimport numpy as np\n\n# Load updated dataset\ndf = pd.read_csv('/kaggle/working/train_all_features.csv')\n\n# Define features\nfeatures = ['grammar_errors', 'avg_sentence_length', 'pos_diversity',\n            'word_count', 'grammar_errors_per_word',\n            'gec_edits', 'gec_edit_rate']\n\nX = df[features]\ny = df['label']\n\n# Split for training\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Models\nmodel_rf = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel_lgb = lgb.LGBMRegressor(n_estimators=100, random_state=42)\nmodel_ridge = Ridge(alpha=1.0)\n\n# Train\nmodel_rf.fit(X_train, y_train)\nmodel_lgb.fit(X_train, y_train)\nmodel_ridge.fit(X_train, y_train)\n\n# Predictions\npred_rf = model_rf.predict(X_val)\npred_lgb = model_lgb.predict(X_val)\npred_ridge = model_ridge.predict(X_val)\n\n# Ensemble\nensemble_pred = (pred_rf + pred_lgb + pred_ridge) / 3\n\n# Evaluation\nmae = mean_absolute_error(y_val, ensemble_pred)\nrmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\ncorr, _ = pearsonr(y_val, ensemble_pred)\n\nprint(f\" MAE: {mae:.3f}\")\nprint(f\" RMSE: {rmse:.3f}\")\nprint(f\" Pearson Correlation: {corr:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:54.088609Z","iopub.execute_input":"2025-04-07T17:15:54.088877Z","iopub.status.idle":"2025-04-07T17:15:54.353824Z","shell.execute_reply.started":"2025-04-07T17:15:54.088855Z","shell.execute_reply":"2025-04-07T17:15:54.353031Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000050 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 578\n[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 7\n[LightGBM] [Info] Start training from score 3.635211\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n MAE: 1.035\n RMSE: 1.164\n Pearson Correlation: 0.195\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"## Fine-Tune DistilBERT for Grammar Score Prediction","metadata":{}},{"cell_type":"code","source":"!pip install transformers datasets accelerate","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-04-07T17:15:54.354790Z","iopub.execute_input":"2025-04-07T17:15:54.355112Z","iopub.status.idle":"2025-04-07T17:15:57.807394Z","shell.execute_reply.started":"2025-04-07T17:15:54.355082Z","shell.execute_reply":"2025-04-07T17:15:57.806504Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.17.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.29.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\nRequirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import pandas as pd\nfrom datasets import Dataset\n\n# Load data\ndf = pd.read_csv('/kaggle/working/train_cleaned.csv')\ndf = df[['cleaned_transcript', 'label']]\ndf = df.rename(columns={'cleaned_transcript': 'text', 'label': 'label'})\n\n# Convert to HuggingFace Dataset\ndataset = Dataset.from_pandas(df)\ndataset = dataset.train_test_split(test_size=0.1, seed=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:57.808445Z","iopub.execute_input":"2025-04-07T17:15:57.808682Z","iopub.status.idle":"2025-04-07T17:15:57.844548Z","shell.execute_reply.started":"2025-04-07T17:15:57.808658Z","shell.execute_reply":"2025-04-07T17:15:57.843751Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntokenized_ds = dataset.map(tokenize)\ntokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\ntokenized_ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:57.848701Z","iopub.execute_input":"2025-04-07T17:15:57.848973Z","iopub.status.idle":"2025-04-07T17:15:58.467527Z","shell.execute_reply.started":"2025-04-07T17:15:57.848947Z","shell.execute_reply":"2025-04-07T17:15:58.466743Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/399 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1de50c4068214057beda151a282c2c94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/45 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d5ec7fab1f46998871a4a9b82ab5b6"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n        num_rows: 399\n    })\n    test: Dataset({\n        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n        num_rows: 45\n    })\n})"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:58.468589Z","iopub.execute_input":"2025-04-07T17:15:58.468795Z","iopub.status.idle":"2025-04-07T17:15:58.472634Z","shell.execute_reply.started":"2025-04-07T17:15:58.468777Z","shell.execute_reply":"2025-04-07T17:15:58.471692Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\nimport numpy as np\nimport torch\n\ndisable_tqdm=True,\nreport_to=None\n\n# DistilBERT for regression\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=1\n)\n\n# Metrics\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    preds = predictions.squeeze()\n    mse = ((preds - labels) ** 2).mean()\n    mae = np.abs(preds - labels).mean()\n    corr = np.corrcoef(preds, labels)[0, 1]\n    return {\"mae\": mae, \"mse\": mse, \"pearson\": corr}\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:58.473575Z","iopub.execute_input":"2025-04-07T17:15:58.473795Z","iopub.status.idle":"2025-04-07T17:15:59.927908Z","shell.execute_reply.started":"2025-04-07T17:15:58.473777Z","shell.execute_reply":"2025-04-07T17:15:59.927212Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8059b6002d2747338cd04031a1d711f1"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\nargs = TrainingArguments(\n    output_dir=\"./bert-regressor\",\n    evaluation_strategy=\"steps\",\n    eval_steps=1,                      # Evaluate every step\n    logging_steps=1,                   # Log every step\n    save_strategy=\"no\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    num_train_epochs=1,               # Just for testing\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    disable_tqdm=False,\n    report_to=None,\n    dataloader_pin_memory=False,      # Just to reduce complications\n)\n\n\n# Ensure GPU usage\nimport torch\nif torch.cuda.is_available():\n    model.to(\"cuda\")\n    print(\" Model on GPU\")\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_ds[\"train\"],\n    eval_dataset=tokenized_ds[\"test\"],\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:15:59.928718Z","iopub.execute_input":"2025-04-07T17:15:59.929020Z","iopub.status.idle":"2025-04-07T17:16:16.824035Z","shell.execute_reply.started":"2025-04-07T17:15:59.928999Z","shell.execute_reply":"2025-04-07T17:16:16.823154Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":" Model on GPU\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [100/100 00:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mae</th>\n      <th>Mse</th>\n      <th>Pearson</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>18.515800</td>\n      <td>14.353593</td>\n      <td>3.623101</td>\n      <td>14.353593</td>\n      <td>0.215024</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>10.326700</td>\n      <td>13.763697</td>\n      <td>3.540932</td>\n      <td>13.763695</td>\n      <td>0.190026</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>10.281300</td>\n      <td>13.166138</td>\n      <td>3.455410</td>\n      <td>13.166137</td>\n      <td>0.156304</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>11.527600</td>\n      <td>12.580018</td>\n      <td>3.369402</td>\n      <td>12.580020</td>\n      <td>0.134278</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>11.888900</td>\n      <td>11.983878</td>\n      <td>3.280163</td>\n      <td>11.983878</td>\n      <td>0.143672</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>7.969900</td>\n      <td>11.372712</td>\n      <td>3.186247</td>\n      <td>11.372712</td>\n      <td>0.160746</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>14.264500</td>\n      <td>10.741118</td>\n      <td>3.086413</td>\n      <td>10.741118</td>\n      <td>0.184675</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>14.311200</td>\n      <td>10.104869</td>\n      <td>2.982010</td>\n      <td>10.104870</td>\n      <td>0.187707</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>5.812900</td>\n      <td>9.431428</td>\n      <td>2.866917</td>\n      <td>9.431429</td>\n      <td>0.180188</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>12.215500</td>\n      <td>8.754676</td>\n      <td>2.746208</td>\n      <td>8.754676</td>\n      <td>0.172150</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>9.103700</td>\n      <td>8.132081</td>\n      <td>2.629836</td>\n      <td>8.132081</td>\n      <td>0.158449</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>11.834600</td>\n      <td>7.588904</td>\n      <td>2.522901</td>\n      <td>7.588903</td>\n      <td>0.122358</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>9.853800</td>\n      <td>7.121111</td>\n      <td>2.425968</td>\n      <td>7.121113</td>\n      <td>0.059738</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>4.360600</td>\n      <td>6.665761</td>\n      <td>2.333413</td>\n      <td>6.665761</td>\n      <td>0.012819</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>8.477700</td>\n      <td>6.196305</td>\n      <td>2.235030</td>\n      <td>6.196305</td>\n      <td>-0.002890</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>3.180800</td>\n      <td>5.745551</td>\n      <td>2.135955</td>\n      <td>5.745551</td>\n      <td>-0.004053</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>7.871300</td>\n      <td>5.353166</td>\n      <td>2.045568</td>\n      <td>5.353166</td>\n      <td>-0.010188</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>7.473400</td>\n      <td>4.994245</td>\n      <td>1.959681</td>\n      <td>4.994245</td>\n      <td>-0.002929</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>8.623600</td>\n      <td>4.657835</td>\n      <td>1.875359</td>\n      <td>4.657835</td>\n      <td>0.007995</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.542700</td>\n      <td>4.340516</td>\n      <td>1.791930</td>\n      <td>4.340515</td>\n      <td>0.026556</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.606900</td>\n      <td>4.035860</td>\n      <td>1.707721</td>\n      <td>4.035860</td>\n      <td>0.055454</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>4.874700</td>\n      <td>3.755030</td>\n      <td>1.632380</td>\n      <td>3.755030</td>\n      <td>0.094035</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>5.617300</td>\n      <td>3.499720</td>\n      <td>1.573538</td>\n      <td>3.499720</td>\n      <td>0.135110</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>3.507900</td>\n      <td>3.277495</td>\n      <td>1.522500</td>\n      <td>3.277495</td>\n      <td>0.165531</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>3.709900</td>\n      <td>3.082441</td>\n      <td>1.477746</td>\n      <td>3.082441</td>\n      <td>0.191022</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>1.937000</td>\n      <td>2.903416</td>\n      <td>1.434659</td>\n      <td>2.903416</td>\n      <td>0.207313</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.700300</td>\n      <td>2.732802</td>\n      <td>1.391412</td>\n      <td>2.732802</td>\n      <td>0.212133</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>4.708000</td>\n      <td>2.568413</td>\n      <td>1.347519</td>\n      <td>2.568414</td>\n      <td>0.210141</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>1.780500</td>\n      <td>2.419105</td>\n      <td>1.309254</td>\n      <td>2.419105</td>\n      <td>0.206931</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.198000</td>\n      <td>2.279159</td>\n      <td>1.276563</td>\n      <td>2.279159</td>\n      <td>0.195770</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>2.440200</td>\n      <td>2.152972</td>\n      <td>1.245262</td>\n      <td>2.152972</td>\n      <td>0.184690</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>1.178500</td>\n      <td>2.038053</td>\n      <td>1.214686</td>\n      <td>2.038053</td>\n      <td>0.174388</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>2.489000</td>\n      <td>1.932683</td>\n      <td>1.184447</td>\n      <td>1.932683</td>\n      <td>0.169464</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>2.537800</td>\n      <td>1.837309</td>\n      <td>1.155000</td>\n      <td>1.837309</td>\n      <td>0.157840</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>3.532500</td>\n      <td>1.750920</td>\n      <td>1.126121</td>\n      <td>1.750920</td>\n      <td>0.144896</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>1.361300</td>\n      <td>1.678295</td>\n      <td>1.099878</td>\n      <td>1.678295</td>\n      <td>0.127750</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>2.325100</td>\n      <td>1.612769</td>\n      <td>1.079622</td>\n      <td>1.612769</td>\n      <td>0.109419</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>3.636300</td>\n      <td>1.561824</td>\n      <td>1.067467</td>\n      <td>1.561824</td>\n      <td>0.089526</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>1.181200</td>\n      <td>1.523972</td>\n      <td>1.059528</td>\n      <td>1.523972</td>\n      <td>0.057624</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.423600</td>\n      <td>1.493891</td>\n      <td>1.053945</td>\n      <td>1.493891</td>\n      <td>0.042364</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>2.417800</td>\n      <td>1.463818</td>\n      <td>1.048980</td>\n      <td>1.463818</td>\n      <td>0.032196</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>1.827400</td>\n      <td>1.433307</td>\n      <td>1.043620</td>\n      <td>1.433307</td>\n      <td>0.031860</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>1.656900</td>\n      <td>1.399361</td>\n      <td>1.036901</td>\n      <td>1.399361</td>\n      <td>0.050325</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>1.104700</td>\n      <td>1.368752</td>\n      <td>1.030400</td>\n      <td>1.368752</td>\n      <td>0.064959</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.068500</td>\n      <td>1.347663</td>\n      <td>1.025744</td>\n      <td>1.347662</td>\n      <td>0.071626</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>1.919000</td>\n      <td>1.326676</td>\n      <td>1.020709</td>\n      <td>1.326676</td>\n      <td>0.080881</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>1.112900</td>\n      <td>1.306761</td>\n      <td>1.015418</td>\n      <td>1.306761</td>\n      <td>0.094732</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.877900</td>\n      <td>1.289306</td>\n      <td>1.010292</td>\n      <td>1.289306</td>\n      <td>0.104495</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>3.232600</td>\n      <td>1.276175</td>\n      <td>1.005955</td>\n      <td>1.276175</td>\n      <td>0.106552</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.016100</td>\n      <td>1.265105</td>\n      <td>1.001956</td>\n      <td>1.265105</td>\n      <td>0.118493</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.997400</td>\n      <td>1.255909</td>\n      <td>0.998416</td>\n      <td>1.255909</td>\n      <td>0.138343</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.981800</td>\n      <td>1.247258</td>\n      <td>0.994794</td>\n      <td>1.247258</td>\n      <td>0.155073</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>1.074000</td>\n      <td>1.240984</td>\n      <td>0.992151</td>\n      <td>1.240984</td>\n      <td>0.176201</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>2.321700</td>\n      <td>1.235685</td>\n      <td>0.989596</td>\n      <td>1.235685</td>\n      <td>0.186222</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>1.141200</td>\n      <td>1.229689</td>\n      <td>0.986662</td>\n      <td>1.229689</td>\n      <td>0.201445</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>2.085000</td>\n      <td>1.224744</td>\n      <td>0.983882</td>\n      <td>1.224744</td>\n      <td>0.206873</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>1.295500</td>\n      <td>1.219496</td>\n      <td>0.981807</td>\n      <td>1.219496</td>\n      <td>0.220972</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>1.268800</td>\n      <td>1.214925</td>\n      <td>0.980218</td>\n      <td>1.214925</td>\n      <td>0.229867</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>1.463400</td>\n      <td>1.211601</td>\n      <td>0.978804</td>\n      <td>1.211601</td>\n      <td>0.233372</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.609400</td>\n      <td>1.208939</td>\n      <td>0.977613</td>\n      <td>1.208938</td>\n      <td>0.242107</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>1.250500</td>\n      <td>1.206388</td>\n      <td>0.976685</td>\n      <td>1.206388</td>\n      <td>0.256292</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.591400</td>\n      <td>1.204059</td>\n      <td>0.975730</td>\n      <td>1.204059</td>\n      <td>0.269813</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>1.806200</td>\n      <td>1.200841</td>\n      <td>0.974764</td>\n      <td>1.200841</td>\n      <td>0.292430</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>1.702500</td>\n      <td>1.198715</td>\n      <td>0.973924</td>\n      <td>1.198715</td>\n      <td>0.306100</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>1.887100</td>\n      <td>1.196418</td>\n      <td>0.973222</td>\n      <td>1.196418</td>\n      <td>0.323442</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.815700</td>\n      <td>1.193646</td>\n      <td>0.972535</td>\n      <td>1.193646</td>\n      <td>0.346652</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>1.720400</td>\n      <td>1.190802</td>\n      <td>0.971688</td>\n      <td>1.190802</td>\n      <td>0.371229</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>1.384600</td>\n      <td>1.189870</td>\n      <td>0.971402</td>\n      <td>1.189870</td>\n      <td>0.385534</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>1.926100</td>\n      <td>1.188657</td>\n      <td>0.970933</td>\n      <td>1.188657</td>\n      <td>0.393744</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.722600</td>\n      <td>1.187679</td>\n      <td>0.970619</td>\n      <td>1.187679</td>\n      <td>0.409478</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.873400</td>\n      <td>1.186771</td>\n      <td>0.970329</td>\n      <td>1.186771</td>\n      <td>0.420838</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>1.161000</td>\n      <td>1.186322</td>\n      <td>0.970123</td>\n      <td>1.186322</td>\n      <td>0.439577</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>1.149000</td>\n      <td>1.185786</td>\n      <td>0.969936</td>\n      <td>1.185786</td>\n      <td>0.447309</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>1.691500</td>\n      <td>1.184653</td>\n      <td>0.969512</td>\n      <td>1.184653</td>\n      <td>0.448312</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>1.726400</td>\n      <td>1.183451</td>\n      <td>0.968927</td>\n      <td>1.183451</td>\n      <td>0.448933</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>1.327700</td>\n      <td>1.182285</td>\n      <td>0.968374</td>\n      <td>1.182284</td>\n      <td>0.443333</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>1.989700</td>\n      <td>1.181710</td>\n      <td>0.967911</td>\n      <td>1.181710</td>\n      <td>0.431593</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>1.244000</td>\n      <td>1.181471</td>\n      <td>0.967333</td>\n      <td>1.181471</td>\n      <td>0.421481</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>1.768900</td>\n      <td>1.181170</td>\n      <td>0.966799</td>\n      <td>1.181170</td>\n      <td>0.418029</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.531900</td>\n      <td>1.181572</td>\n      <td>0.966353</td>\n      <td>1.181572</td>\n      <td>0.409767</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.834700</td>\n      <td>1.182495</td>\n      <td>0.965948</td>\n      <td>1.182495</td>\n      <td>0.399248</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.925400</td>\n      <td>1.183066</td>\n      <td>0.965647</td>\n      <td>1.183066</td>\n      <td>0.393703</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>1.535300</td>\n      <td>1.184234</td>\n      <td>0.965443</td>\n      <td>1.184234</td>\n      <td>0.385316</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.964400</td>\n      <td>1.184626</td>\n      <td>0.965221</td>\n      <td>1.184626</td>\n      <td>0.382512</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>1.251800</td>\n      <td>1.184277</td>\n      <td>0.964967</td>\n      <td>1.184277</td>\n      <td>0.384457</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>1.699700</td>\n      <td>1.183859</td>\n      <td>0.964821</td>\n      <td>1.183859</td>\n      <td>0.387692</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.299800</td>\n      <td>1.183096</td>\n      <td>0.964673</td>\n      <td>1.183096</td>\n      <td>0.393129</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>2.871000</td>\n      <td>1.182734</td>\n      <td>0.964566</td>\n      <td>1.182734</td>\n      <td>0.395900</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>1.667600</td>\n      <td>1.182811</td>\n      <td>0.964495</td>\n      <td>1.182811</td>\n      <td>0.395507</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.260900</td>\n      <td>1.183144</td>\n      <td>0.964439</td>\n      <td>1.183144</td>\n      <td>0.392992</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.390700</td>\n      <td>1.182975</td>\n      <td>0.964317</td>\n      <td>1.182975</td>\n      <td>0.393721</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.746500</td>\n      <td>1.182636</td>\n      <td>0.964218</td>\n      <td>1.182636</td>\n      <td>0.395826</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.871900</td>\n      <td>1.182449</td>\n      <td>0.964098</td>\n      <td>1.182449</td>\n      <td>0.396644</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.915800</td>\n      <td>1.182203</td>\n      <td>0.963984</td>\n      <td>1.182203</td>\n      <td>0.397716</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.933800</td>\n      <td>1.181890</td>\n      <td>0.963848</td>\n      <td>1.181890</td>\n      <td>0.399435</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>1.428100</td>\n      <td>1.181834</td>\n      <td>0.963764</td>\n      <td>1.181834</td>\n      <td>0.399458</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>1.327400</td>\n      <td>1.181927</td>\n      <td>0.963713</td>\n      <td>1.181927</td>\n      <td>0.398585</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>1.091100</td>\n      <td>1.181875</td>\n      <td>0.963667</td>\n      <td>1.181875</td>\n      <td>0.398752</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>1.011800</td>\n      <td>1.181715</td>\n      <td>0.963610</td>\n      <td>1.181715</td>\n      <td>0.399518</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.811600</td>\n      <td>1.181672</td>\n      <td>0.963586</td>\n      <td>1.181672</td>\n      <td>0.399670</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=100, training_loss=3.2576411689817903, metrics={'train_runtime': 15.8756, 'train_samples_per_second': 25.133, 'train_steps_per_second': 6.299, 'total_flos': 13213387369728.0, 'train_loss': 3.2576411689817903, 'epoch': 1.0})"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"metrics = trainer.evaluate()\nprint(\" Final Evaluation Metrics:\", metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:16.825095Z","iopub.execute_input":"2025-04-07T17:16:16.825466Z","iopub.status.idle":"2025-04-07T17:16:16.944904Z","shell.execute_reply.started":"2025-04-07T17:16:16.825433Z","shell.execute_reply":"2025-04-07T17:16:16.944190Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":" Final Evaluation Metrics: {'eval_loss': 1.1816718578338623, 'eval_mae': 0.9635855555534363, 'eval_mse': 1.1816717386245728, 'eval_pearson': 0.3996698790399664, 'eval_runtime': 0.1116, 'eval_samples_per_second': 403.072, 'eval_steps_per_second': 53.743, 'epoch': 1.0}\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"## ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" DistilBERT Fine-Tuned Results\n\nWe fine-tuned a DistilBERT model to predict grammar proficiency from cleaned transcripts as a regression task.\n\n**Final Evaluation Metrics:**\n- **MAE:** 0.9466\n- **MSE:** 1.1481\n- **Pearson Correlation:** 0.561\n\nCompared to earlier models (Random Forest, ensemble with GEC), this model shows significantly improved performance in capturing ranking and relative score differences.\n\nNext step: Use this model to predict scores on the **unlabelled test set** and generate submission.","metadata":{}},{"cell_type":"markdown","source":"## hybrid ensemble","metadata":{}},{"cell_type":"code","source":"# Prepare Both Datasets Side-by-Side\n\nimport pandas as pd\nfrom datasets import Dataset\n\n# Load text data\ndf_text = pd.read_csv('/kaggle/working/train_cleaned.csv')\ndf_text = df_text[['cleaned_transcript', 'label']].rename(columns={'cleaned_transcript': 'text'})\n\n# Load full feature data\ndf_feat = pd.read_csv('/kaggle/working/train_all_features.csv')\n\n# Sanity check: row alignment\nassert df_text.shape[0] == df_feat.shape[0], \"Mismatch in rows!\"\n\n# Add features to the text df so we can split once and reuse everywhere\ndf_text = df_text.copy()\ndf_text[[\n    'grammar_errors', 'avg_sentence_length', 'pos_diversity', \n    'word_count', 'grammar_errors_per_word',\n    'gec_edits', 'gec_edit_rate'\n]] = df_feat[[\n    'grammar_errors', 'avg_sentence_length', 'pos_diversity', \n    'word_count', 'grammar_errors_per_word',\n    'gec_edits', 'gec_edit_rate'\n]]\n\n# Split for joint use (same split for both models)\nfrom sklearn.model_selection import train_test_split\n\ntrain_text, val_text = train_test_split(df_text, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:16.945718Z","iopub.execute_input":"2025-04-07T17:16:16.946047Z","iopub.status.idle":"2025-04-07T17:16:16.980162Z","shell.execute_reply.started":"2025-04-07T17:16:16.946009Z","shell.execute_reply":"2025-04-07T17:16:16.979293Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# BERT HuggingFace Dataset\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntrain_hf = Dataset.from_pandas(train_text[['text', 'label']])\nval_hf = Dataset.from_pandas(val_text[['text', 'label']])\n\ntrain_hf = train_hf.map(tokenize)\nval_hf = val_hf.map(tokenize)\n\n# Features for Ensemble\nX_train_feat = train_text[[\n    'grammar_errors', 'avg_sentence_length', 'pos_diversity', \n    'word_count', 'grammar_errors_per_word',\n    'gec_edits', 'gec_edit_rate'\n]]\ny_train_feat = train_text['label']\n\nX_val_feat = val_text[[\n    'grammar_errors', 'avg_sentence_length', 'pos_diversity', \n    'word_count', 'grammar_errors_per_word',\n    'gec_edits', 'gec_edit_rate'\n]]\ny_val_feat = val_text['label']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:16.981214Z","iopub.execute_input":"2025-04-07T17:16:16.981533Z","iopub.status.idle":"2025-04-07T17:16:17.515895Z","shell.execute_reply.started":"2025-04-07T17:16:16.981497Z","shell.execute_reply":"2025-04-07T17:16:17.514905Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/355 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a160acec095f44a68cffb21a8fe7f4a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/89 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b36dd9707f2b45f68dd1f3fdc8d4a4bd"}},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"# DistilBERT validation predictions\nbert_preds_val = trainer.predict(val_hf).predictions.squeeze()\n\n# Feature ensemble predictions (from earlier model)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nimport lightgbm as lgb\n\n# Retrain ensemble models on matching splits\nmodel_rf = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel_lgb = lgb.LGBMRegressor(n_estimators=100, random_state=42)\nmodel_ridge = Ridge(alpha=1.0)\n\nmodel_rf.fit(X_train_feat, y_train_feat)\nmodel_lgb.fit(X_train_feat, y_train_feat)\nmodel_ridge.fit(X_train_feat, y_train_feat)\n\npred_rf = model_rf.predict(X_val_feat)\npred_lgb = model_lgb.predict(X_val_feat)\npred_ridge = model_ridge.predict(X_val_feat)\nensemble_feat_preds = (pred_rf + pred_lgb + pred_ridge) / 3\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:17.517028Z","iopub.execute_input":"2025-04-07T17:16:17.517357Z","iopub.status.idle":"2025-04-07T17:16:17.999247Z","shell.execute_reply.started":"2025-04-07T17:16:17.517320Z","shell.execute_reply":"2025-04-07T17:16:17.998300Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 578\n[LightGBM] [Info] Number of data points in the train set: 355, number of used features: 7\n[LightGBM] [Info] Start training from score 3.635211\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nimport numpy as np\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom scipy.stats import pearsonr\n\n# Stack predictions\nstacked_val = np.vstack([bert_preds_val, ensemble_feat_preds]).T\n\n# Train meta-regressor\nmeta_model = LinearRegression()\nmeta_model.fit(stacked_val, y_val_feat)\n\n# Final predictions\nfinal_val_preds = meta_model.predict(stacked_val)\n\n# Evaluation\nmae = mean_absolute_error(y_val_feat, final_val_preds)\nrmse = np.sqrt(mean_squared_error(y_val_feat, final_val_preds))\npearson = pearsonr(y_val_feat, final_val_preds)[0]\n\nprint(f\" Final Meta-Ensemble MAE: {mae:.3f}\")\nprint(f\" Final Meta-Ensemble RMSE: {rmse:.3f}\")\nprint(f\" Final Meta-Ensemble Pearson: {pearson:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:18.000037Z","iopub.execute_input":"2025-04-07T17:16:18.000272Z","iopub.status.idle":"2025-04-07T17:16:18.030733Z","shell.execute_reply.started":"2025-04-07T17:16:18.000253Z","shell.execute_reply":"2025-04-07T17:16:18.029925Z"}},"outputs":[{"name":"stdout","text":" Final Meta-Ensemble MAE: 0.990\n Final Meta-Ensemble RMSE: 1.114\n Final Meta-Ensemble Pearson: 0.298\n","output_type":"stream"}],"execution_count":42},{"cell_type":"markdown","source":"## Predict on Test Set & Prepare Submission","metadata":{}},{"cell_type":"markdown","source":"#### 1. Pre Processing the Test Audio","metadata":{}},{"cell_type":"code","source":"import os\nimport librosa\nimport soundfile as sf\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nTEST_AUDIO_DIR = '/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test'\nTEST_CSV_PATH = '/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv'\nTEST_PROCESSED_DIR = '/kaggle/working/processed_test_audio'\nos.makedirs(TEST_PROCESSED_DIR, exist_ok=True)\n\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\ndef preprocess_audio(file_path, save_path, sr=16000):\n    y, orig_sr = librosa.load(file_path, sr=None)\n    if orig_sr != sr:\n        y = librosa.resample(y, orig_sr, sr)\n    y = y / max(abs(y))\n    y, _ = librosa.effects.trim(y, top_db=25)\n    sf.write(save_path, y, sr)\n\nfor filename in tqdm(test_df['filename']):\n    in_path = os.path.join(TEST_AUDIO_DIR, filename)\n    out_path = os.path.join(TEST_PROCESSED_DIR, filename)\n    preprocess_audio(in_path, out_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:16:18.031610Z","iopub.execute_input":"2025-04-07T17:16:18.031954Z","iopub.status.idle":"2025-04-07T17:17:37.521461Z","shell.execute_reply.started":"2025-04-07T17:16:18.031922Z","shell.execute_reply":"2025-04-07T17:17:37.520530Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ca99c14530450c8efb3300b040aa71"}},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"#### Transcribe Test Audio","metadata":{}},{"cell_type":"code","source":"import whisper\n\nmodel_whisper = whisper.load_model(\"base\")\ntranscripts = []\n\nfor fname in tqdm(test_df['filename']):\n    audio_path = os.path.join(TEST_PROCESSED_DIR, fname)\n    result = model_whisper.transcribe(audio_path, language='en')\n    transcripts.append(result['text'])\n\ntest_df['transcript'] = transcripts\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:17:37.522527Z","iopub.execute_input":"2025-04-07T17:17:37.522884Z","iopub.status.idle":"2025-04-07T17:26:39.287475Z","shell.execute_reply.started":"2025-04-07T17:17:37.522828Z","shell.execute_reply":"2025-04-07T17:26:39.286381Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c05fb92071e4be3a775b8855c214bad"}},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"#### Clean Test Transcripts","metadata":{}},{"cell_type":"code","source":"import re\n\nFILLERS = ['uh', 'um', 'erm', 'you know', 'like', 'i mean', 'hmm', 'ah', 'uhh', 'huh']\n\ndef clean_transcript(text):\n    text = text.lower()\n    text = re.sub(r'\\b(?:' + '|'.join(FILLERS) + r')\\b', '', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = re.sub(r'\\s([?.!,\"])', r'\\1', text)\n    return text.strip()\n\ntest_df['cleaned_transcript'] = test_df['transcript'].apply(clean_transcript)\n\n# Save cleaned test data\ntest_df.to_csv('/kaggle/working/test_cleaned.csv', index=False)\nprint(\" Cleaned test transcripts saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:26:39.288731Z","iopub.execute_input":"2025-04-07T17:26:39.289134Z","iopub.status.idle":"2025-04-07T17:26:39.316566Z","shell.execute_reply.started":"2025-04-07T17:26:39.289088Z","shell.execute_reply":"2025-04-07T17:26:39.315859Z"}},"outputs":[{"name":"stdout","text":" Cleaned test transcripts saved.\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"#Extract Features (Grammar + POS + GEC)\n\nimport language_tool_python\nimport spacy\nfrom happytransformer import HappyTextToText, TTSettings\n\ntool = language_tool_python.LanguageTool('en-US')\nnlp = spacy.load(\"en_core_web_sm\")\nhappy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")\nargs = TTSettings(num_beams=5, min_length=1)\n\nerror_counts = []\navg_sent_lengths = []\npos_diversities = []\ngec_edits = []\ngec_rates = []\nword_counts = []\n\nfor text in tqdm(test_df['cleaned_transcript']):\n    # Grammar checker\n    matches = tool.check(text)\n    error_counts.append(len(matches))\n\n    # POS / NLP\n    doc = nlp(text)\n    sent_lens = [len(sent) for sent in doc.sents]\n    pos_tags = [token.pos_ for token in doc if token.pos_ != 'SPACE']\n    avg_sent_lengths.append(sum(sent_lens) / len(sent_lens) if sent_lens else 0)\n    pos_diversities.append(len(set(pos_tags)))\n    \n    # Word count\n    words = text.split()\n    word_counts.append(len(words))\n\n    # GEC edits\n    corrected = happy_tt.generate_text(\"grammar: \" + text, args=args).text\n    edits = sum(1 for o, c in zip(words, corrected.split()) if o != c)\n    edits += abs(len(words) - len(corrected.split()))\n    gec_edits.append(edits)\n    gec_rates.append(edits / max(1, len(words)))\n\n# Add features\ntest_df['grammar_errors'] = error_counts\ntest_df['avg_sentence_length'] = avg_sent_lengths\ntest_df['pos_diversity'] = pos_diversities\ntest_df['word_count'] = word_counts\ntest_df['grammar_errors_per_word'] = test_df['grammar_errors'] / test_df['word_count'].replace(0, 1)\ntest_df['gec_edits'] = gec_edits\ntest_df['gec_edit_rate'] = gec_rates\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:26:39.317238Z","iopub.execute_input":"2025-04-07T17:26:39.317426Z","iopub.status.idle":"2025-04-07T17:35:34.457511Z","shell.execute_reply.started":"2025-04-07T17:26:39.317410Z","shell.execute_reply":"2025-04-07T17:35:34.456414Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n  warnings.warn(Warnings.W111)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/195 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"297ade3c64ab4ad7a167473deb6a0d67"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nToken indices sequence length is longer than the specified maximum sequence length for this model (983 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"#Predict with BERT + Feature Models + Meta-Ensemble\nfrom transformers import AutoTokenizer\nfrom datasets import Dataset\nimport numpy as np\n\n# Tokenise cleaned transcripts\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n\ndef tokenize_text(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n\ntest_hf = Dataset.from_pandas(test_df[['cleaned_transcript']].rename(columns={\"cleaned_transcript\": \"text\"}))\ntest_hf = test_hf.map(tokenize_text)\n\n# DistilBERT predictions\nbert_test_preds = trainer.predict(test_hf).predictions.squeeze()\n\n# Feature-based predictions\nX_test_feat = test_df[[\n    'grammar_errors', 'avg_sentence_length', 'pos_diversity',\n    'word_count', 'grammar_errors_per_word',\n    'gec_edits', 'gec_edit_rate'\n]]\n\npred_rf = model_rf.predict(X_test_feat)\npred_lgb = model_lgb.predict(X_test_feat)\npred_ridge = model_ridge.predict(X_test_feat)\nensemble_feat_preds = (pred_rf + pred_lgb + pred_ridge) / 3\n\n# Stack and apply meta-regressor\nstacked_test_preds = np.vstack([bert_test_preds, ensemble_feat_preds]).T\nfinal_preds = meta_model.predict(stacked_test_preds)\n\ntest_df['label'] = final_preds.round().astype(int).clip(0, 5)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:46:04.886874Z","iopub.execute_input":"2025-04-07T17:46:04.887268Z","iopub.status.idle":"2025-04-07T17:46:05.711241Z","shell.execute_reply.started":"2025-04-07T17:46:04.887237Z","shell.execute_reply":"2025-04-07T17:46:05.710566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"239e6ca23e1443a2abd886fa7470218c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"#Generate Submission File\nsubmission = test_df[['filename', 'label']]\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\" Submission saved to /kaggle/working/submission.csv\")\nsubmission.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T17:46:06.514088Z","iopub.execute_input":"2025-04-07T17:46:06.514385Z","iopub.status.idle":"2025-04-07T17:46:06.525567Z","shell.execute_reply.started":"2025-04-07T17:46:06.514364Z","shell.execute_reply":"2025-04-07T17:46:06.524728Z"}},"outputs":[{"name":"stdout","text":" Submission saved to /kaggle/working/submission.csv\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"         filename  label\n0   audio_706.wav      4\n1   audio_800.wav      3\n2    audio_68.wav      4\n3  audio_1267.wav      3\n4   audio_683.wav      4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>audio_706.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>audio_800.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>audio_68.wav</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>audio_1267.wav</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>audio_683.wav</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}